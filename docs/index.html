<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>MOSS-Speech | Towards True Speech-to-Speech Models</title>
    <meta name="description" content="MOSS-Speech: A true speech-to-speech foundation model without text guidance. Direct speech understanding and generation, preserving paralinguistic cues with low latency and high expressivity." />
    <link rel="icon" href="assets/illustrations/logo.png" type="image/png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="assets/style.css" />
  </head>
  <body>
    <header class="site-header">
      <div class="container header-inner">
        <div class="brand">
          <img src="assets/illustrations/logo.png" alt="Logo" class="logo" />
          <span class="brand-name">MOSS-Speech</span>
        </div>
        <nav class="nav">
          <a href="#features">Features</a>
          <a href="#demos">Demo Videos</a>
          <a href="https://moss-speech-demo.open-moss.com" target="_blank" rel="noreferrer">Online Demo</a>
          <a href="https://github.com/OpenMOSS/MOSS-Speech" target="_blank" rel="noreferrer">GitHub</a>
          <a href="https://github.com/OpenMOSS/MOSS-Speech/blob/main/papers/MOSS-Speech%20Technical%20Report.pdf" target="_blank" rel="noreferrer">Technical Report</a>
        </nav>
      </div>
    </header>

    <main>
      <section class="hero">
        <div class="container">
          <div class="hero-logo" role="img" aria-label="MOSS-Speech logo">
            <img src="assets/illustrations/logo.png" alt="MOSS-Speech logo" />
          </div>
          <div class="hero-title">
            <h1>MOSS-Speech: Towards True Speech-to-Speech Models Without Text Guidance</h1>
            <div class="title-divider"></div>
          </div>
          <div class="hero-inner">
            <div class="hero-copy">
              <!-- <p class="subtitle">Speech is the most natural modality for human communication and a compelling target for human‚Äìcomputer interaction. Conventional voice assistants adopt a cascaded pipeline‚Äîautomatic speech recognition (ASR) ‚Üí large language model (LLM) text generation ‚Üí text-to-speech (TTS)‚Äîwhich, despite its maturity, discards fine-grained prosodic cues such as intonation, emotion, and pauses, limiting conversational naturalness. Recent ‚Äúend-to-end‚Äù systems have shown promise, yet most still require an intermediate textual representation during generation, using text as guidance before producing speech. This compromise reduces both efficiency and expressive capacity.</p> -->
              <p class="subtitle">MOSS-Speech introduces true end-to-end speech interaction. Unlike cascaded pipelines or text-guided models, it directly generates speech without first producing text. This design preserves intonation, emotion, and other paralinguistic cues, while retaining the knowledge of the pretrained textual LLM‚Äîenabling more natural and efficient speech-to-speech dialogue.</p>
              <div class="cta-row">
              <a class="btn" href="#demos">Demo Videos</a>
              <a class="btn" href="https://huggingface.co/spaces/fnlp/MOSS-Speech" target="_blank" rel="noreferrer">Try Online Demo</a>
              <a class="btn" href="https://github.com/OpenMOSS/MOSS-Speech" target="_blank" rel="noreferrer">GitHub</a>
              <a class="btn" href="https://github.com/OpenMOSS/MOSS-Speech/blob/main/papers/MOSS-Speech%20Technical%20Report.pdf" target="_blank" rel="noreferrer">Technical Report</a>
            </div>
          </div>
        </div>
      </section>

      <section id="features" class="section">
        <div class="container">
          <h2>Features</h2>
          <div class="features-grid">
            <div class="feature">
              <div class="emoji">üéØ</div>
              <h3>True Speech-to-Speech Large Language Model</h3>
              <p>MOSS-Speech understands and generates speech directly ‚Äî no text guidance required. It can capture and generate emotion, laughter, and other paralinguistic information, enabling more natural and efficient interaction.</p>
            </div>
            <div class="feature">
              <div class="emoji">üîß</div>
              <h3>New Architecture for Modality Alignment</h3>
              <p>Built upon a pretrained text LLM, MOSS-Speech introduces modality-layered design with frozen pretraining. This allows the model to retain the abilities of the text LLM while natively adding speech understanding and generation capabilities.</p>
            </div>
            <div class="feature">
              <div class="emoji">üìä</div>
              <h3>Native Multimodal Support</h3>
              <p>MOSS-Speech handles both speech and text seamlessly, supporting flexible multimodal interaction including: Speech ‚Üí Speech, Text ‚Üí Speech, Speech ‚Üí Text, and Text ‚Üí Text.</p>
            </div>
          </div>
        </div>
      </section>

      <section id="demos" class="section">
  <div class="container">
    <div class="section-head">
      <h2>Demo </h2>
      <p class="note-inline">Model inference segments in the videos have been time-accelerated.</p>
      <div class="filters">
        <button class="chip is-active" data-filter="all">All</button>
        <button class="chip" data-filter="zh">Chinese</button>
        <button class="chip" data-filter="en">English</button>
      </div>
    </div>
    <div id="demo-grid" class="demo-grid" aria-live="polite"></div>
  </div>
</section>


    </main>

    <footer class="site-footer">
      <div class="container footer-inner">
        <span>¬© <span id="year"></span> MOSS-Speech</span>
      </div>
    </footer>

    <script src="assets/app.js"></script>
  </body>
  </html>


