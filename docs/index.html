<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>MOSS-Speech | Towards True Speech-to-Speech Models</title>
    <meta name="description" content="MOSS-Speech: A true speech-to-speech foundation model without text guidance. Direct speech understanding and generation, preserving paralinguistic cues with low latency and high expressivity." />
    <link rel="icon" href="assets/illustrations/logo.png" type="image/png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="assets/style.css" />
  </head>
  <body>
    <header class="site-header">
      <div class="container header-inner">
        <div class="brand">
          <img src="assets/illustrations/logo.png" alt="Logo" class="logo" />
          <span class="brand-name">MOSS-Speech</span>
        </div>
        <nav class="nav">
          <a href="#features">Features</a>
          <a href="#demos">Demos</a>
          <a href="https://github.com/OpenMOSS/MOSS-Speech" target="_blank" rel="noreferrer">GitHub</a>
        </nav>
      </div>
    </header>

    <main>
      <section class="hero">
        <div class="container">
          <div class="hero-title">
            <h1>MOSS-Speech: Towards True Speech-to-Speech Models Without Text Guidance</h1>
            <div class="title-divider"></div>
          </div>
          <div class="hero-inner">
            <div class="hero-copy">
              <p class="subtitle">Speech is the most natural modality for human communication and a compelling target for human‚Äìcomputer interaction. Conventional voice assistants adopt a cascaded pipeline‚Äîautomatic speech recognition (ASR) ‚Üí large language model (LLM) text generation ‚Üí text-to-speech (TTS)‚Äîwhich, despite its maturity, discards fine-grained prosodic cues such as intonation, emotion, and pauses, limiting conversational naturalness. Recent ‚Äúend-to-end‚Äù systems have shown promise, yet most still require an intermediate textual representation during generation, using text as guidance before producing speech. This compromise reduces both efficiency and expressive capacity.</p>
              <p class="subtitle">MOSS-Speech marks a shift to true end-to-end speech interaction: it performs speech-to-speech generation without first materializing text prompts, while retaining strong reasoning capabilities typically associated with text-centric LLMs. By eliminating the mandatory text bottleneck, MOSS-Speech enables more faithful prosody preservation and more fluid, natural dialogues, advancing the field toward seamless, fully acoustic human‚ÄìAI conversation.</p>
              <div class="cta-row">
              <a class="btn" href="#demos">Try Demos</a>
              <a class="btn" href="https://github.com/OpenMOSS/MOSS-Speech" target="_blank" rel="noreferrer">Learn More</a>
              </div>
            </div>
          </div>
        </div>
      </section>

      <section id="features" class="section">
        <div class="container">
          <h2>Highlights</h2>
          <div class="features-grid">
            <div class="feature">
              <div class="emoji">üéØ</div>
              <h3>True Speech-to-Speech LLM</h3>
              <p>Directly processes speech for both understanding and generation, preserving intonation, affect, laughter, and pauses for natural, efficient conversations.</p>
            </div>
            <div class="feature">
              <div class="emoji">üîß</div>
              <h3>Modality-Aligned Architecture</h3>
              <p>Built on a pretrained text LLM with modality-specific layers over shared reasoning cores, enabling native speech comprehension and synthesis while retaining strong reasoning.</p>
            </div>
            <div class="feature">
              <div class="emoji">üìä</div>
              <h3>Bimodal I/O Support</h3>
              <p>Enables flexible cross-modal communication by supporting all combinations of speech and text: speech‚Üíspeech, text‚Üíspeech, speech‚Üítext, and text‚Üítext.</p>
            </div>
          </div>
        </div>
      </section>

      <section id="demos" class="section">
  <div class="container">
    <div class="section-head">
      <h2>Demo </h2>
      <p class="note-inline">Model inference segments in the videos have been time-accelerated.</p>
      <div class="filters">
        <button class="chip is-active" data-filter="all">All</button>
        <button class="chip" data-filter="zh">Chinese</button>
        <button class="chip" data-filter="en">English</button>
      </div>
    </div>
    <div id="demo-grid" class="demo-grid" aria-live="polite"></div>
  </div>
</section>


    </main>

    <footer class="site-footer">
      <div class="container footer-inner">
        <span>¬© <span id="year"></span> MOSS-Speech</span>
      </div>
    </footer>

    <script src="assets/app.js"></script>
  </body>
  </html>


